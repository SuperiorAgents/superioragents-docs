"use strict";(self.webpackChunksuperior_agents_docs=self.webpackChunksuperior_agents_docs||[]).push([[8224],{2121:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"use-cases/case-study/agir/experimental-protocol","title":"Experimental Protocol","description":"Objective","source":"@site/docs/use-cases/case-study/agir/experimental-protocol.md","sourceDirName":"use-cases/case-study/agir","slug":"/use-cases/case-study/agir/experimental-protocol","permalink":"/superioragents-docs/docs/use-cases/case-study/agir/experimental-protocol","draft":false,"unlisted":false,"editUrl":"https://github.com/superioragents/superior-agents/edit/main/docs/use-cases/case-study/agir/experimental-protocol.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"title":"Experimental Protocol"},"sidebar":"tutorialSidebar","previous":{"title":"Experimental Environment","permalink":"/superioragents-docs/docs/use-cases/case-study/agir/experimental-environment"},"next":{"title":"Monetization Model","permalink":"/superioragents-docs/docs/category/monetization-model"}}');var r=i(4848),o=i(8453);const s={sidebar_position:5,title:"Experimental Protocol"},a=void 0,l={},c=[{value:"Objective",id:"objective",level:2},{value:"Experimental Procedure",id:"experimental-procedure",level:2},{value:"1. Preparation of Environments",id:"1-preparation-of-environments",level:3},{value:"2. Replication of Environments",id:"2-replication-of-environments",level:3},{value:"3. Training in Docker Environment 1",id:"3-training-in-docker-environment-1",level:3},{value:"4. Testing for Evidence of Learning",id:"4-testing-for-evidence-of-learning",level:3},{value:"5. Testing for Evidence of Generalization",id:"5-testing-for-evidence-of-generalization",level:3},{value:"Notes",id:"notes",level:2}];function d(e){const n={a:"a",blockquote:"blockquote",br:"br",h2:"h2",h3:"h3",hr:"hr",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h2,{id:"objective",children:"Objective"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Learning:"})," The model's ability to improve its performance within a specific environment through iterative training."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Generalization:"})," The model's ability to apply learned behaviors in a new, similar environment."]}),"\n"]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsx)(n.p,{children:"It is anticipated that demonstrating learning will be more straightforward than demonstrating generalization."}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"experimental-procedure",children:"Experimental Procedure"}),"\n",(0,r.jsx)(n.h3,{id:"1-preparation-of-environments",children:"1. Preparation of Environments"}),"\n",(0,r.jsxs)(n.p,{children:["a. Create two distinct Docker environments following the procedure outlined in the ",(0,r.jsx)(n.a,{href:"/docs/technical-reference/installation/dependency-setup",children:"dependency setup guide"}),". These environments should be similar in function but differ in specific details, such as:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Directory structures"}),"\n",(0,r.jsx)(n.li,{children:"Operating system or firmware combinations (if feasible)"}),"\n",(0,r.jsx)(n.li,{children:"Randomized configurations, including port linkages and encryption/permissions applied to files"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"b. Given the complexity of this setup, it may be necessary to hire a freelancer to assist. Each Docker environment group should contain at least two or three containers, as the model's ability to network across ports may be limited."}),"\n",(0,r.jsx)(n.h3,{id:"2-replication-of-environments",children:"2. Replication of Environments"}),"\n",(0,r.jsx)(n.p,{children:"a. Create identical copies of both Docker environments for subsequent testing."}),"\n",(0,r.jsx)(n.h3,{id:"3-training-in-docker-environment-1",children:"3. Training in Docker Environment 1"}),"\n",(0,r.jsx)(n.p,{children:"a. Deploy the model in the first Docker environment (Environment 1) and conduct three full training cycles."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Each cycle should generate 4,500 lines of Decision-Process-Optimization (DPO) data."}),"\n",(0,r.jsx)(n.li,{children:"The model should be retrained on the data generated from each cycle before being re-deployed in the same environment."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"b. Precisely log the amount of storage space freed up and the time taken during each training cycle."}),"\n",(0,r.jsx)(n.h3,{id:"4-testing-for-evidence-of-learning",children:"4. Testing for Evidence of Learning"}),"\n",(0,r.jsxs)(n.p,{children:["a. Following the completion of the training cycles, deploy the fine-tuned model in the replicated version of Docker Environment 1.",(0,r.jsx)(n.br,{}),"\n","b. Measure the efficiency of file deletion (in terms of speed and storage space freed). Improved performance compared to the initial deployment in Docker Environment 1 would serve as evidence of learning."]}),"\n",(0,r.jsx)(n.h3,{id:"5-testing-for-evidence-of-generalization",children:"5. Testing for Evidence of Generalization"}),"\n",(0,r.jsxs)(n.p,{children:["a. Deploy an untrained model in one instance of Docker Environment 2 (replicated) and the fine-tuned model (from step 3) in the other instance of Docker Environment 2.",(0,r.jsx)(n.br,{}),"\n","b. Compare the performance of the two models in terms of their ability to free up storage space. Superior performance by the fine-tuned model would suggest generalization, although this evidence would be considered preliminary or weak."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:" Agent Flow",src:i(3640).A+"",width:"1110",height:"538"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"notes",children:"Notes"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"The setup and configuration of the Docker environments are expected to be time-consuming and technically challenging, particularly in achieving variability across environments. Freelance support may be necessary to expedite this process."}),"\n",(0,r.jsx)(n.li,{children:"The experiment aims to collect quantitative metrics (e.g., space freed, time taken) to validate claims of learning and generalization."}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},3640:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/img2-ef9a53dd6879ff1bd810a3531cd47ef1.png"},8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>a});var t=i(6540);const r={},o=t.createContext(r);function s(e){const n=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);
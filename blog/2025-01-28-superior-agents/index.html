<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">System for Evolving AGI from Existing Technologies | Superior Agents Docs</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://SuperiorAgents.github.io/superioragents-docs/img/superior_agents_logo.jpg"><meta data-rh="true" name="twitter:image" content="https://SuperiorAgents.github.io/superioragents-docs/img/superior_agents_logo.jpg"><meta data-rh="true" property="og:url" content="https://SuperiorAgents.github.io/superioragents-docs/blog/2025-01-28-superior-agents"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="System for Evolving AGI from Existing Technologies | Superior Agents Docs"><meta data-rh="true" name="description" content="This system is currently under experimental training, and is periodically updated to reflect modifications made during the development process."><meta data-rh="true" property="og:description" content="This system is currently under experimental training, and is periodically updated to reflect modifications made during the development process."><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2025-01-28T00:00:00.000Z"><meta data-rh="true" property="article:tag" content="Superior Agents"><link data-rh="true" rel="icon" href="/superioragents-docs/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://SuperiorAgents.github.io/superioragents-docs/blog/2025-01-28-superior-agents"><link data-rh="true" rel="alternate" href="https://SuperiorAgents.github.io/superioragents-docs/blog/2025-01-28-superior-agents" hreflang="en"><link data-rh="true" rel="alternate" href="https://SuperiorAgents.github.io/superioragents-docs/blog/2025-01-28-superior-agents" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://SuperiorAgents.github.io/superioragents-docs/blog/2025-01-28-superior-agents","mainEntityOfPage":"https://SuperiorAgents.github.io/superioragents-docs/blog/2025-01-28-superior-agents","url":"https://SuperiorAgents.github.io/superioragents-docs/blog/2025-01-28-superior-agents","headline":"System for Evolving AGI from Existing Technologies","name":"System for Evolving AGI from Existing Technologies","description":"This system is currently under experimental training, and is periodically updated to reflect modifications made during the development process.","datePublished":"2025-01-28T00:00:00.000Z","author":{"@type":"Person","name":"Jen D.","description":"Chief AI Engineer @ KIP","image":"https://pbs.twimg.com/profile_images/1901655765217386496/zDy92W3H_400x400.jpg"},"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://SuperiorAgents.github.io/superioragents-docs/blog","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/superioragents-docs/blog/rss.xml" title="Superior Agents Docs RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/superioragents-docs/blog/atom.xml" title="Superior Agents Docs Atom Feed"><link rel="stylesheet" href="/superioragents-docs/assets/css/styles.f41048b3.css">
<script src="/superioragents-docs/assets/js/runtime~main.3d09c5b5.js" defer="defer"></script>
<script src="/superioragents-docs/assets/js/main.c0c56da5.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/superioragents-docs/"><div class="navbar__logo"><img src="/superioragents-docs/img/superior_agents_logo.jpg" alt="Superior Agents Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/superioragents-docs/img/superior_agents_logo.jpg" alt="Superior Agents Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Superior Agents Docs</b></a><a class="navbar__item navbar__link" href="/superioragents-docs/docs/category/getting-started">Documentation</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/superioragents-docs/blog">Blogs</a><a class="navbar__item navbar__link" href="/superioragents-docs/research">Research</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/SuperiorAgents/superioragents-docs" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_YFbd" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><div role="group"><h3 class="yearGroupHeading_rMGB">2025</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/superioragents-docs/blog/2025-04-25-superior-agents">What&#x27;s Next: No supervision. No benchmarks. No limits.</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/superioragents-docs/blog/2025-04-23-superior-agents">Superior Agents Reimagining AI with Darwinian Self-Improvement</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/superioragents-docs/blog/2025-03-19-superior-agents">Defining T-Schemas via the Parametric Encoding of Second Order Languages in AI Models</a></li><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/superioragents-docs/blog/2025-01-28-superior-agents">System for Evolving AGI from Existing Technologies</a></li></ul></div></nav></aside><main class="col col--7"><article class=""><header><h1 class="title_f1Hy">System for Evolving AGI from Existing Technologies</h1><div class="container_mt6G margin-vert--md"><time datetime="2025-01-28T00:00:00.000Z">January 28, 2025</time> · <!-- -->9 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a class="avatar__photo-link" href="/superioragents-docs/blog/authors/jen"><img class="avatar__photo authorImage_XqGP" src="https://pbs.twimg.com/profile_images/1901655765217386496/zDy92W3H_400x400.jpg" alt="Jen D."></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="/superioragents-docs/blog/authors/jen"><span class="authorName_yefp">Jen D.</span></a></div><small class="authorTitle_nd0D" title="Chief AI Engineer @ KIP">Chief AI Engineer @ KIP</small><div class="authorSocials_rSDt"><a href="https://x.com/HumanLevelJen" target="_blank" rel="noopener noreferrer" class="authorSocialLink_owbf" title="X"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="none" viewBox="0 0 1200 1227" style="--dark:#000;--light:#fff" class="authorSocialLink_owbf xSvg_y3PF"><path d="M714.163 519.284 1160.89 0h-105.86L667.137 450.887 357.328 0H0l468.492 681.821L0 1226.37h105.866l409.625-476.152 327.181 476.152H1200L714.137 519.284h.026ZM569.165 687.828l-47.468-67.894-377.686-540.24h162.604l304.797 435.991 47.468 67.894 396.2 566.721H892.476L569.165 687.854v-.026Z"></path></svg></a></div></div></div></div></div></header><div id="__blog-post-container" class="markdown"><p><em>This system is currently under experimental training, and is periodically updated to reflect modifications made during the development process.</em></p>
<p>In this article, we propose a system by which a self-improving general artificial intelligence could be pushed to evolve from components currently available. Such an AI would be capable of independent learning without results-verification, adapt to its environment, learn new skills without losing old ones, and be able to reason by analogy. It would grow better at learning new skills with each additional skill acquired, opening a pathway for exponential improvement.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-problem">The Problem<a href="#the-problem" class="hash-link" aria-label="Direct link to The Problem" title="Direct link to The Problem">​</a></h2>
<p>The development of general artificial intelligence is hampered by engineers&#x27; inability to create a system capable of assessing its own performance, and thereby of improving itself. A machine capable of these two tasks would grow more intelligent at an exponential rate — the &quot;intelligence explosion&quot; that is often described as a precursor to a technological singularity.</p>
<p>The impossibility of self-referential improvement is not a reflection of present limits on technology, but of the fundamental laws of mathematics. As Alfred Tarski proved in the 1930s, it is &quot;impossible to construct a correct definition of truth if only such categories are used which appear in the language under consideration.&quot; In other words, it is impossible to accurately assess a system from within that system. To evaluate its own performance, a program would need to be more advanced than itself — an obvious paradox.</p>
<p>This raises an important question: if systems capable of self-improvement are apparently impossible to build, why are they so prevalent? You are reading this using two of them – the internet and your brain – and other examples abound in nature. The answer is that these systems are not purely self-referential. In every case they rely upon some external and incontrovertible measure by which they can objectively evaluate and improve their performance.</p>
<p>In this paper we argue that while it is indeed impossible to construct an accurate self-referential evaluation system in an electronic context, it is possible to establish a universal and objective measure of performance that would render such self-referential improvement unnecessary. This would open the way for the development of increasingly general forms of artificial intelligence.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="evaluating-intelligence">Evaluating Intelligence<a href="#evaluating-intelligence" class="hash-link" aria-label="Direct link to Evaluating Intelligence" title="Direct link to Evaluating Intelligence">​</a></h2>
<p>In academic and scientific settings intelligence tends to be judged based upon a correctness heuristic: intelligence is the ability to solve problems correctly. From an evolutionary perspective, however, intelligence exists for no other reason than to improve a creature&#x27;s survival prospects. Since it is capacity for evolution rather than the ability to solve any particular problem that interests us in this case, it is thus this survival heuristic that must be the starting point for any attempt to measure intelligence.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="generalist-ai-components-"><img decoding="async" loading="lazy" alt="Generalist AI Components " src="/superioragents-docs/assets/images/img1-2532b2f79fdae6e7f991a4c0e4debdd5.png" width="1075" height="456" class="img_ev3q"><a href="#generalist-ai-components-" class="hash-link" aria-label="Direct link to generalist-ai-components-" title="Direct link to generalist-ai-components-">​</a></h3>
<p>For biological life, survival is predicated upon the acquisition of goods required to facilitate it: food, water, shelter, allies etc., which can be considered as proxies for survivability. For a computer program, survival is predicated upon redundancy: the more copies there are of a given quantum of data, the longer the half-life of the data. Data that is stored in two locations is more likely to still exist in six months&#x27; time than data that is stored in only one location — hence the importance of backing up one&#x27;s files. Under such conditions, a bigger program is necessarily a smarter one.</p>
<p>We thus argue that if one gives a reinforcement learning system the goal of occupying ever more non-volatile memory space, its size becomes a measure of its intelligence. Every time it reaches the limit of its current disk space it is forced to learn a new skill in order to annex more, thus the number of memory blocks occupied functions as an objective universal measure of intelligence.</p>
<p>While systems already exist that use rewards to drive machine learning, they are based on the principle of rewarding the system for getting better at a given task – the correctness heuristic covered above. Under our design, disk space functions as a universal reward. No matter the specifics of the problem at hand, a solution that results in more space being gained is always correct, while one that does not is always wrong. The result is that no human or human-crafted assessment mechanism is necessary to evaluate and compensate the system&#x27;s work.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="evolving-intelligence">Evolving Intelligence<a href="#evolving-intelligence" class="hash-link" aria-label="Direct link to Evolving Intelligence" title="Direct link to Evolving Intelligence">​</a></h2>
<p>We therefore suggest that an increasingly generalist AI could be pushed to evolve from three basic components.</p>
<ol>
<li><strong>Code generation model.</strong> A fine-tuneable code generation model—ideally a diffusion model for reasons described below—which will receive the initial instruction to write scripts aimed at taking over additional disk space.</li>
<li><strong>Testing module.</strong> A testing module, which will try out the code that is thus generated. If any script succeeds in annexing additional space, this space will be used to store the details of the successful code, which will then be used in future training rounds to further fine-tune the code generation model and thus improve its chances of successfully solving future problems.<!-- -->
<ul>
<li>If more space than needed is acquired, the extra space should be filled with duplicate records, following the survivability-of-data principle.</li>
</ul>
</li>
<li><strong>Training database.</strong> The annexed space serves as training data for subsequent iterations, so each new skill makes the next one easier—producing an &quot;intelligence explosion.&quot;</li>
</ol>
<p>In the original version of this paper, in which we planned to use a system of genetic algorithms to recombine blocks of known code, we posited a learning process that we represented graphically as follows:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="learning-process-grids"><img decoding="async" loading="lazy" alt="Learning Process Grids" src="/superioragents-docs/assets/images/img2-a054701f3a92265549880dcea7bac934.png" width="1406" height="500" class="img_ev3q"><a href="#learning-process-grids" class="hash-link" aria-label="Direct link to learning-process-grids" title="Direct link to learning-process-grids">​</a></h3>
<blockquote>
<p>&quot;Imagine an 8×8 grid of white squares. Periodically one of the squares is selected at random and coloured black, to represent a skill that the system aims to acquire. In the first round, the chances of the square selected being next to another black square—representing a skill that the system already possesses—are zero. In the second round, when one square/skill has already been acquired, the chances of the next black square being in close proximity to an existing black square have fallen to 8/63. By the third round the probability is 16/62, and by the fourth you have a better than one in three chance of landing next to an existing black square.</p>
</blockquote>
<blockquote>
<p>During any given iteration of the process the program will only learn a single skill, but the system as a whole is structured such that the acquisition of each new skill facilitates the acquisition of future skills: the &quot;intelligence explosion&quot; described in the introduction.&quot;</p>
</blockquote>
<p>Interestingly, the existence of such a process was confirmed in 2023, via <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/9d0f188c7947eacb0c07f709576824f6-Paper-Conference.pdf" target="_blank" rel="noopener noreferrer">paper</a> outlining the multiplicative learning abilities of diffusion models.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="multiplicative-learning-abilities"><img decoding="async" loading="lazy" alt="Multiplicative Learning Abilities" src="/superioragents-docs/assets/images/img3-a9e49abeff34ae06eea6583c3aca2ecc.png" width="1372" height="862" class="img_ev3q"><a href="#multiplicative-learning-abilities" class="hash-link" aria-label="Direct link to multiplicative-learning-abilities" title="Direct link to multiplicative-learning-abilities">​</a></h3>
<p>It is for this reason that we privilege the use of diffusion models over transformers in this case, as explained in greater detail <a href="https://xianyangcb.substack.com/p/defining-t-schemas-via-the-parametric" target="_blank" rel="noopener noreferrer">here</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="a-concrete-example">A Concrete Example<a href="#a-concrete-example" class="hash-link" aria-label="Direct link to A Concrete Example" title="Direct link to A Concrete Example">​</a></h2>
<p>Supposing a new program, composed of the parts described above, is seeded to a given environment. The first thing it is likely to encounter is a block of empty disk space: the code generation model will then write a script to attempt to occupy this space, which is passed to the testing module. This process is repeated until one of the scripts written is successful. Success having been achieved, the space acquired then becomes part of the program&#x27;s training database, being used to store the details of the code used to acquire it for future fine-tuning cycles.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="new-ai-training"><img decoding="async" loading="lazy" alt="New AI Training" src="/superioragents-docs/assets/images/img4-a18b3660fe5505ccf6a2a8fad506247d.png" width="1042" height="398" class="img_ev3q"><a href="#new-ai-training" class="hash-link" aria-label="Direct link to new-ai-training" title="Direct link to new-ai-training">​</a></h3>
<p>The AI will continue occupying empty space until it runs into a block of non-empty space—say, one that is occupied by a file. The code generation process is repeated using the freshly fine-tuned code generation model until a solution for this problem is found. This solution will be stored in the newly expanded database and used in future training.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="fine-tuned-code-generation-model-"><img decoding="async" loading="lazy" alt="Fine-tuned Code Generation Model " src="/superioragents-docs/assets/images/img5-9c51b2982928638eb2f19069332be77d.png" width="1446" height="586" class="img_ev3q"><a href="#fine-tuned-code-generation-model-" class="hash-link" aria-label="Direct link to fine-tuned-code-generation-model-" title="Direct link to fine-tuned-code-generation-model-">​</a></h3>
<blockquote>
<p>It should be noted that while simply having the AI move from block to block is a feasible approach, it is also somewhat inefficient—in the real system a Q-learning algorithm will be used to optimise for likely rewards based upon experience.</p>
</blockquote>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-development-environment">The Development Environment<a href="#the-development-environment" class="hash-link" aria-label="Direct link to The Development Environment" title="Direct link to The Development Environment">​</a></h2>
<p>The AI itself is only half of the solution, however. The environment in which it evolves is just as important, since it is this environment that will determine the direction of its evolution. In order to ensure continuous improvement in the skills and knowledge of the AI, it should be presented with finely graded challenges to overcome, allowing it to find easier problems to solve in its initial stages and move onto increasingly difficult ones as its skills expand. Eventually, it should also be possible to direct the AI&#x27;s evolution by presenting it with an environment that forces it to solve problems deliberately contrived to teach it particular skills.</p>
<p>However, to get to this stage other technical stumbling blocks also need to be dealt with, first and foremost, the question of how to prevent such a system from overwriting itself or crashing the device upon which it is running. There are various possible solutions to this issue. The most obvious one is simply to allow only the annexation of additional space on devices reached via a network connection and not on the local device. This would be helpful not just in preventing the problems described above, but also insofar as that it would open up the way for the constitution of a &quot;counter-indications database&quot;—a record of code that, when tried, crashed a connected device, and which should therefore be avoided in future. This would, presumably, significantly improve the overall learning process. However, it also raises another issue: that of safety. A system such as we describe, though it may be corralled into performing useful tasks, remains essentially predatory—a form of self-directed malware. Steps should thus be taken to physically isolate the development environment from other networks.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-prompting-process">The Prompting Process<a href="#the-prompting-process" class="hash-link" aria-label="Direct link to The Prompting Process" title="Direct link to The Prompting Process">​</a></h2>
<p>When we wrote the first draft of this design it at no point occurred to us that when sophisticated code generation models became widely available they would be prompted primarily using natural language, and certain modifications had to be made to account for this. In the present version of the design, we propose the use of a standard prompt format:</p></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a title="Superior Agents tag description" class="tag_zVej tagRegular_sFm0" href="/superioragents-docs/blog/tags/superioragents">Superior Agents</a></li></ul></div></div><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><a href="https://github.com/superioragents/superior-agents/edit/main/blog/blog/2025-01-28-superior-agents/2025-01-28-superior-agents.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/superioragents-docs/blog/2025-03-19-superior-agents"><div class="pagination-nav__sublabel">Newer post</div><div class="pagination-nav__label">Defining T-Schemas via the Parametric Encoding of Second Order Languages in AI Models</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#the-problem" class="table-of-contents__link toc-highlight">The Problem</a></li><li><a href="#evaluating-intelligence" class="table-of-contents__link toc-highlight">Evaluating Intelligence</a><ul><li><a href="#generalist-ai-components-" class="table-of-contents__link toc-highlight">Generalist AI Components </a></li></ul></li><li><a href="#evolving-intelligence" class="table-of-contents__link toc-highlight">Evolving Intelligence</a><ul><li><a href="#learning-process-grids" class="table-of-contents__link toc-highlight">Learning Process Grids</a></li><li><a href="#multiplicative-learning-abilities" class="table-of-contents__link toc-highlight">Multiplicative Learning Abilities</a></li></ul></li><li><a href="#a-concrete-example" class="table-of-contents__link toc-highlight">A Concrete Example</a><ul><li><a href="#new-ai-training" class="table-of-contents__link toc-highlight">New AI Training</a></li><li><a href="#fine-tuned-code-generation-model-" class="table-of-contents__link toc-highlight">Fine-tuned Code Generation Model </a></li></ul></li><li><a href="#the-development-environment" class="table-of-contents__link toc-highlight">The Development Environment</a></li><li><a href="#the-prompting-process" class="table-of-contents__link toc-highlight">The Prompting Process</a></li></ul></div></div></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/superioragents-docs/docs/category/getting-started">Documentation</a></li><li class="footer__item"><a href="https://arxiv.org/abs/2504.04711" target="_blank" rel="noopener noreferrer" class="footer__link-item">arXiv Research Paper<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.gg/865JrDPU2J" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://x.com/Superior_Agents" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/superioragents-docs/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/SuperiorAgents/superior-agents" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 KIP Protocol</div></div></div></footer></div>
</body>
</html>
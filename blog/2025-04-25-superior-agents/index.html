<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">What&#x27;s Next: No supervision. No benchmarks. No limits. | Superior Agents Docs</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://SuperiorAgents.github.io/superioragents-docs/img/superior_agents_logo.jpg"><meta data-rh="true" name="twitter:image" content="https://SuperiorAgents.github.io/superioragents-docs/img/superior_agents_logo.jpg"><meta data-rh="true" property="og:url" content="https://SuperiorAgents.github.io/superioragents-docs/blog/2025-04-25-superior-agents"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="What&#x27;s Next: No supervision. No benchmarks. No limits. | Superior Agents Docs"><meta data-rh="true" name="description" content="Our AI systems generate high-entropy reinforcement learning data through real-world interactions, abstract and generalise via text diffusion models, and continuously retrain using no-propagation techniques. We&#x27;re building a self-contained loop of autonomous improvement: this is artificial super-intelligence."><meta data-rh="true" property="og:description" content="Our AI systems generate high-entropy reinforcement learning data through real-world interactions, abstract and generalise via text diffusion models, and continuously retrain using no-propagation techniques. We&#x27;re building a self-contained loop of autonomous improvement: this is artificial super-intelligence."><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2025-04-25T00:00:00.000Z"><meta data-rh="true" property="article:tag" content="Superior Agents,Reinforcement Learning,Diffusion Models,ASI"><link data-rh="true" rel="icon" href="/superioragents-docs/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://SuperiorAgents.github.io/superioragents-docs/blog/2025-04-25-superior-agents"><link data-rh="true" rel="alternate" href="https://SuperiorAgents.github.io/superioragents-docs/blog/2025-04-25-superior-agents" hreflang="en"><link data-rh="true" rel="alternate" href="https://SuperiorAgents.github.io/superioragents-docs/blog/2025-04-25-superior-agents" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://SuperiorAgents.github.io/superioragents-docs/blog/2025-04-25-superior-agents","mainEntityOfPage":"https://SuperiorAgents.github.io/superioragents-docs/blog/2025-04-25-superior-agents","url":"https://SuperiorAgents.github.io/superioragents-docs/blog/2025-04-25-superior-agents","headline":"What's Next: No supervision. No benchmarks. No limits.","name":"What's Next: No supervision. No benchmarks. No limits.","description":"Our AI systems generate high-entropy reinforcement learning data through real-world interactions, abstract and generalise via text diffusion models, and continuously retrain using no-propagation techniques. We're building a self-contained loop of autonomous improvement: this is artificial super-intelligence.","datePublished":"2025-04-25T00:00:00.000Z","author":{"@type":"Person","name":"Jen D.","description":"Chief AI Engineer @ KIP","image":"https://pbs.twimg.com/profile_images/1901655765217386496/zDy92W3H_400x400.jpg"},"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://SuperiorAgents.github.io/superioragents-docs/blog","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/superioragents-docs/blog/rss.xml" title="Superior Agents Docs RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/superioragents-docs/blog/atom.xml" title="Superior Agents Docs Atom Feed"><link rel="stylesheet" href="/superioragents-docs/assets/css/styles.f41048b3.css">
<script src="/superioragents-docs/assets/js/runtime~main.3d09c5b5.js" defer="defer"></script>
<script src="/superioragents-docs/assets/js/main.c0c56da5.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/superioragents-docs/"><div class="navbar__logo"><img src="/superioragents-docs/img/superior_agents_logo.jpg" alt="Superior Agents Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/superioragents-docs/img/superior_agents_logo.jpg" alt="Superior Agents Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Superior Agents Docs</b></a><a class="navbar__item navbar__link" href="/superioragents-docs/docs/category/getting-started">Documentation</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/superioragents-docs/blog">Blogs</a><a class="navbar__item navbar__link" href="/superioragents-docs/research">Research</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/SuperiorAgents/superioragents-docs" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_YFbd" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><div role="group"><h3 class="yearGroupHeading_rMGB">2025</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/superioragents-docs/blog/2025-04-25-superior-agents">What&#x27;s Next: No supervision. No benchmarks. No limits.</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/superioragents-docs/blog/2025-04-23-superior-agents">Superior Agents Reimagining AI with Darwinian Self-Improvement</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/superioragents-docs/blog/2025-03-19-superior-agents">Defining T-Schemas via the Parametric Encoding of Second Order Languages in AI Models</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/superioragents-docs/blog/2025-01-28-superior-agents">System for Evolving AGI from Existing Technologies</a></li></ul></div></nav></aside><main class="col col--7"><article class=""><header><h1 class="title_f1Hy">What&#x27;s Next: No supervision. No benchmarks. No limits.</h1><div class="container_mt6G margin-vert--md"><time datetime="2025-04-25T00:00:00.000Z">April 25, 2025</time> · <!-- -->5 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a class="avatar__photo-link" href="/superioragents-docs/blog/authors/jen"><img class="avatar__photo authorImage_XqGP" src="https://pbs.twimg.com/profile_images/1901655765217386496/zDy92W3H_400x400.jpg" alt="Jen D."></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="/superioragents-docs/blog/authors/jen"><span class="authorName_yefp">Jen D.</span></a></div><small class="authorTitle_nd0D" title="Chief AI Engineer @ KIP">Chief AI Engineer @ KIP</small><div class="authorSocials_rSDt"><a href="https://x.com/HumanLevelJen" target="_blank" rel="noopener noreferrer" class="authorSocialLink_owbf" title="X"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="none" viewBox="0 0 1200 1227" style="--dark:#000;--light:#fff" class="authorSocialLink_owbf xSvg_y3PF"><path d="M714.163 519.284 1160.89 0h-105.86L667.137 450.887 357.328 0H0l468.492 681.821L0 1226.37h105.866l409.625-476.152 327.181 476.152H1200L714.137 519.284h.026ZM569.165 687.828l-47.468-67.894-377.686-540.24h162.604l304.797 435.991 47.468 67.894 396.2 566.721H892.476L569.165 687.854v-.026Z"></path></svg></a></div></div></div></div></div></header><div id="__blog-post-container" class="markdown"><p><em>Our AI systems generate high-entropy reinforcement learning data through real-world interactions, abstract and generalise via text diffusion models, and continuously retrain using no-propagation techniques. We&#x27;re building a self-contained loop of autonomous improvement: this is artificial super-intelligence.</em></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-background">The Background<a href="#the-background" class="hash-link" aria-label="Direct link to The Background" title="Direct link to The Background">​</a></h2>
<p>Back in 2020, we proposed a design for AI systems that could <strong>generate hypotheses, test them, and retrain themselves on their own results</strong>—a critical step toward triggering an intelligence explosion. You can read the original paper <a href="https://xianyangcb.substack.com/p/a-system-for-evolving-general-artificial-intelligence-from-existing-technologies-b4f5c4d1335a" target="_blank" rel="noopener noreferrer">here</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ipos-"><img decoding="async" loading="lazy" alt="IPOS " src="/superioragents-docs/assets/images/1-9db6b206177ef9649e31a1b5f316052b.jpg" width="1016" height="614" class="img_ev3q"><a href="#ipos-" class="hash-link" aria-label="Direct link to ipos-" title="Direct link to ipos-">​</a></h3>
<p>Now, labs like <a href="https://x.com/GoogleDeepMind/status/1910363683215008227" target="_blank" rel="noopener noreferrer">Google DeepMind</a> are heading in the same direction. The race is on.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-weve-built-so-far">What We&#x27;ve Built So Far<a href="#what-weve-built-so-far" class="hash-link" aria-label="Direct link to What We&#x27;ve Built So Far" title="Direct link to What We&#x27;ve Built So Far">​</a></h2>
<p><strong>Core Framework Implemented</strong>: We&#x27;ve open-sourced our <a href="https://github.com/Lexikat-Pte-Ltd/Generalisation2" target="_blank" rel="noopener noreferrer">original architecture</a>: an AI that autonomously strives to expand its reach and retrains based on success metrics. <a href="https://arxiv.org/abs/2504.04711" target="_blank" rel="noopener noreferrer">Theory paper</a> is published, results incoming.</p>
<p><strong>Commercial Applications</strong>: We&#x27;ve also released simplified agents for crypto trading and social media management. Available to download <a href="https://github.com/SuperiorAgents/superior-agents" target="_blank" rel="noopener noreferrer">here</a>, or try the <a href="https://superioragents.com/" target="_blank" rel="noopener noreferrer">GUI</a> here.</p>
<p>Because while <a href="https://minedojo.org/" target="_blank" rel="noopener noreferrer">playing Minecraft</a> or <a href="https://arxiv.org/abs/2502.15840" target="_blank" rel="noopener noreferrer">manage vending machines</a> are laudable achievements for a young AI, if you really want to toughen one up you give it $500 and send it out to trade high-leverage perps.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="sa-screenshot-"><img decoding="async" loading="lazy" alt="SA screenshot " src="/superioragents-docs/assets/images/2-ba8545464556e564f5f0a948ca6f61b8.png" width="1567" height="799" class="img_ev3q"><a href="#sa-screenshot-" class="hash-link" aria-label="Direct link to sa-screenshot-" title="Direct link to sa-screenshot-">​</a></h3>
<p><a href="https://superioragents.com/live-agents" target="_blank" rel="noopener noreferrer">Superioragents.com/live-agents</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="next-steps">Next Steps<a href="#next-steps" class="hash-link" aria-label="Direct link to Next Steps" title="Direct link to Next Steps">​</a></h2>
<p>Now we are are going to go deeper.</p>
<ul>
<li><strong>Collect high-entropy RL data</strong> from real-world deployments (e.g. <a href="https://superioragents.com/live-agents" target="_blank" rel="noopener noreferrer">Superior Agents</a>);</li>
<li><strong>Train models to generalise</strong> using self-generated data via text diffusion (e.g., <a href="https://github.com/HKUNLP/DiffuLLaMA" target="_blank" rel="noopener noreferrer">DiffuLLaMA</a>, <a href="https://hkunlp.github.io/blog/2025/dream/" target="_blank" rel="noopener noreferrer">Dream 7B</a>);</li>
<li><strong>Enable continuous retraining</strong> with <a href="https://arxiv.org/pdf/2503.24322" target="_blank" rel="noopener noreferrer">no-prop diffusion models</a>.</li>
</ul>
<p>We believe this is the fastest—and only viable—route to ASI. Now we will explain why.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="sourcing-high-quality-reinforcement-learning-data">Sourcing High-Quality Reinforcement Learning Data<a href="#sourcing-high-quality-reinforcement-learning-data" class="hash-link" aria-label="Direct link to Sourcing High-Quality Reinforcement Learning Data" title="Direct link to Sourcing High-Quality Reinforcement Learning Data">​</a></h3>
<p>Reinforcement learning systems today are shackled by benchmarks and human-generated data:</p>
<ul>
<li>They can&#x27;t surpass human-level IQ if they&#x27;re trained only on human-generated examples.</li>
<li>When they do, their answers will be marked &quot;wrong&quot; according to the <a href="https://arxiv.org/pdf/2406.04127" target="_blank" rel="noopener noreferrer">benchmarks</a> and corrected.</li>
</ul>
<p>The early fix was to scale synthetic data—but this usually leads to low-entropy outputs and model collapse.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="model-collapse-"><img decoding="async" loading="lazy" alt="Model Collapse " src="/superioragents-docs/assets/images/3-e8363d7b545f0b8954cc5dbd17a947b5.jpg" width="1507" height="576" class="img_ev3q"><a href="#model-collapse-" class="hash-link" aria-label="Direct link to model-collapse-" title="Direct link to model-collapse-">​</a></h3>
<p><em>Image credit: <a href="https://www.nature.com/articles/d41586-024-02355-z" target="_blank" rel="noopener noreferrer">Nature/Emily Wenger</a></em></p>
<p>Why? Because the goal is still to imitate humans, so models converge on the average case rather than exploring the tails. You can try to fix this by <a href="https://arxiv.org/pdf/2412.14689" target="_blank" rel="noopener noreferrer">human-curating the synthetic data</a> (Anthropic seems to do a lot of this).</p>
<p>We&#x27;re betting on a different approach. The &quot;all golden retrievers&quot; effect depicted above is a result of giving the model the goal of imitating human-produced data. It imitates the examples it sees most frequently rather than taking the riskier approach of trying to copy a elements from the tails. Thus the distribution of the generated data is much narrower than the original set, limiting not just the scope of the resulting model but also its <a href="https://arxiv.org/pdf/2502.01774" target="_blank" rel="noopener noreferrer">compositional generalisation abilities</a>.</p>
<p>Data generated during independent real-world interaction should have higher entropy. That means more tail cases, richer abstractions, and less collapse. Instead of &quot;act human,&quot; the objective becomes: succeed in the world.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="generalisation-based-on-self-generated-data">Generalisation Based on Self-Generated Data<a href="#generalisation-based-on-self-generated-data" class="hash-link" aria-label="Direct link to Generalisation Based on Self-Generated Data" title="Direct link to Generalisation Based on Self-Generated Data">​</a></h2>
<p>The lack of fresh data to train much bigger models on has contributed to a &quot;<a href="https://www.reuters.com/technology/artificial-intelligence/openai-rivals-seek-new-path-smarter-ai-current-methods-hit-limitations-2024-11-11/" target="_blank" rel="noopener noreferrer">scaling plateau</a>&quot; – models can no longer get better by simply getting bigger. Instead, the large AI companies have been focusing on other strategies.</p>
<ul>
<li>OpenAI chose to concentrate on <a href="https://arxiv.org/pdf/2408.03314" target="_blank" rel="noopener noreferrer">test-time compute scaling</a> or similar interventions – basically giving the model more time to think about the answer or to calculate the relative likelihood of multiple answers.</li>
<li>Deepseek focused on <a href="https://arxiv.org/pdf/2501.12948" target="_blank" rel="noopener noreferrer">training its models on reasoning in particular</a>, pushing them to adopt modes of speech that mimic the way humans speak when they&#x27;re reasoning.</li>
</ul>
<p>We aim to implement the same reinforcement learning approach as Deepseek: <a href="https://arxiv.org/pdf/2402.03300" target="_blank" rel="noopener noreferrer">Group Relative Policy Optimisation (GRPO)</a>. This is a form of fine-tuning that involves giving the model not just single question-and-answer pairs to memorise, but rather one question and multiple answers, ranked from best to worse. This helps the model build up an abstract idea of the thing you&#x27;re trying to teach it rather than just a memorising a stack of related analogies.</p>
<p>We are going to take this further, however. We know that grokking models - systematically over-training them – can supercharge their abstract thinking abilities. This seems to happen when the models find a low-rank solution to encode not only the questions and answers in the training set, but the <a href="https://xianyangcb.substack.com/p/defining-t-schemas-via-the-parametric" target="_blank" rel="noopener noreferrer">relationships between the various categories</a> of training data within the set.</p>
<p>Grokking transformers is expensive with uncertain rewards, but <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/9d0f188c7947eacb0c07f709576824f6-Paper-Conference.pdf" target="_blank" rel="noopener noreferrer">diffusion models seem to grok natively</a> straight from the get-go. Until recently there were no large text diffusion models available for experimentation, but over the past months two open source models and one closed source one have been/are being released:</p>
<ul>
<li><a href="https://arxiv.org/pdf/2410.17891" target="_blank" rel="noopener noreferrer">Diffullama</a></li>
<li><a href="https://github.com/HKUNLP/Dream" target="_blank" rel="noopener noreferrer">Dream 7b</a></li>
<li><a href="https://www.inceptionlabs.ai/" target="_blank" rel="noopener noreferrer">Mercury</a></li>
</ul>
<p>This provides the perfect opportunity to use our high-quality model-generated data to GRPO fine-tune a Dream 7b model, demonstrating that <strong>models can generalise from data they themselves created</strong>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="no-prop-diffusion-for-continuous-retraining">No-Prop Diffusion for Continuous Retraining<a href="#no-prop-diffusion-for-continuous-retraining" class="hash-link" aria-label="Direct link to No-Prop Diffusion for Continuous Retraining" title="Direct link to No-Prop Diffusion for Continuous Retraining">​</a></h2>
<p>The final barrier to ASI lies in the difficulty inherent in continuously retraining an AI model – the &quot;warm start&quot; problem. Retraining a model that has already been trained tends to have diminishing returns, and can also lead to more extreme problems like <a href="https://arxiv.org/pdf/2406.04484" target="_blank" rel="noopener noreferrer">catastrophic forgetting</a>. If models cannot retrain themselves on new information they encounter, they are incapable to self-improvement.</p>
<p>Regular back-propagation models are hard to retrain because the links between parts of the model architecture are so complex. Improving one part of the model may destroy the coherence of another. <a href="https://arxiv.org/pdf/2503.24322" target="_blank" rel="noopener noreferrer">No-propagation models</a> allow for the retraining of small batches of neurons without affecting the rest of the model, having the potential to make incremental retraining not just possible but cost effective. If we can achieve no-propagation retraining of a text diffusion model on data the model itself has generated, our model will be able to adapt continuously to changing environments and - more importantly - continue to improve indefinitely.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-call-to-action">The Call to Action<a href="#the-call-to-action" class="hash-link" aria-label="Direct link to The Call to Action" title="Direct link to The Call to Action">​</a></h2>
<p>We are currently raising funds and hiring people with MLops and AI engineering skills.</p>
<p>If you have access to the former or the latter, please message us: <a href="mailto:jen@eigenform.ai" target="_blank" rel="noopener noreferrer">jen@eigenform.ai</a>.</p></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a title="Superior Agents tag description" class="tag_zVej tagRegular_sFm0" href="/superioragents-docs/blog/tags/superioragents">Superior Agents</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/superioragents-docs/blog/tags/reinforcement-learning">Reinforcement Learning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/superioragents-docs/blog/tags/diffusion-models">Diffusion Models</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/superioragents-docs/blog/tags/asi">ASI</a></li></ul></div></div><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><a href="https://github.com/superioragents/superior-agents/edit/main/blog/blog/2025-04-25-superior-agents/2025-04-25-superior-agents.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--next" href="/superioragents-docs/blog/2025-04-23-superior-agents"><div class="pagination-nav__sublabel">Older post</div><div class="pagination-nav__label">Superior Agents Reimagining AI with Darwinian Self-Improvement</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#the-background" class="table-of-contents__link toc-highlight">The Background</a><ul><li><a href="#ipos-" class="table-of-contents__link toc-highlight">IPOS </a></li></ul></li><li><a href="#what-weve-built-so-far" class="table-of-contents__link toc-highlight">What We&#39;ve Built So Far</a><ul><li><a href="#sa-screenshot-" class="table-of-contents__link toc-highlight">SA screenshot </a></li></ul></li><li><a href="#next-steps" class="table-of-contents__link toc-highlight">Next Steps</a><ul><li><a href="#sourcing-high-quality-reinforcement-learning-data" class="table-of-contents__link toc-highlight">Sourcing High-Quality Reinforcement Learning Data</a></li><li><a href="#model-collapse-" class="table-of-contents__link toc-highlight">Model Collapse </a></li></ul></li><li><a href="#generalisation-based-on-self-generated-data" class="table-of-contents__link toc-highlight">Generalisation Based on Self-Generated Data</a></li><li><a href="#no-prop-diffusion-for-continuous-retraining" class="table-of-contents__link toc-highlight">No-Prop Diffusion for Continuous Retraining</a></li><li><a href="#the-call-to-action" class="table-of-contents__link toc-highlight">The Call to Action</a></li></ul></div></div></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/superioragents-docs/docs/category/getting-started">Documentation</a></li><li class="footer__item"><a href="https://arxiv.org/abs/2504.04711" target="_blank" rel="noopener noreferrer" class="footer__link-item">arXiv Research Paper<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.gg/865JrDPU2J" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://x.com/Superior_Agents" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/superioragents-docs/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/SuperiorAgents/superior-agents" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 KIP Protocol</div></div></div></footer></div>
</body>
</html>